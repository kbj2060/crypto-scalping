"""
PPO ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€í•˜ê³  ì„±ëŠ¥ ì§€í‘œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
"""
import logging
import os
import sys
import numpy as np
import pandas as pd
import torch
from datetime import datetime

# ìƒìœ„ í´ë”ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import config
from core import DataCollector
from strategies import (
    BTCEthCorrelationStrategy, VolatilitySqueezeStrategy, OrderblockFVGStrategy,
    HMAMomentumStrategy, MFIMomentumStrategy, BollingerMeanReversionStrategy,
    VWAPDeviationStrategy, RangeTopBottomStrategy, StochRSIMeanReversionStrategy,
    CMFDivergenceStrategy,
    CCIReversalStrategy, WilliamsRStrategy
)

from model.trading_env import TradingEnvironment
from model.ppo_agent import PPOAgent
from model.preprocess import DataPreprocessor

# ë¡œê¹… ì„¤ì •
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/evaluate_ppo.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë¡œê·¸ ë„ê¸°
logging.getLogger('model.feature_engineering').setLevel(logging.WARNING)
logging.getLogger('model.mtf_processor').setLevel(logging.WARNING)


class PPOModelEvaluator:
    """PPO ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path=None, scaler_path=None):
        """
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
            scaler_path: ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
            Note: ë°ì´í„° ë¶„í• ì€ train_ppo.pyì™€ ë™ì¼í•˜ê²Œ 70:15:15 ê¸°ì¤€ì„ ë”°ë¦„
        """
        self.model_path = model_path or config.AI_MODEL_PATH
        self.scaler_path = scaler_path or config.AI_MODEL_PATH.replace('.pth', '_scaler.pkl')
        
        # 1. ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        self.data_collector = DataCollector(use_saved_data=True)
        
        # 2. ì „ëµ ì´ˆê¸°í™” (train_ppo.pyì™€ ë™ì¼)
        self.breakout_strategies = []
        self.range_strategies = []
        
        # í­ë°œì¥ ì „ëµ
        if config.STRATEGIES.get('btc_eth_correlation', False):
            self.breakout_strategies.append(BTCEthCorrelationStrategy())
        if config.STRATEGIES.get('volatility_squeeze', False):
            self.breakout_strategies.append(VolatilitySqueezeStrategy())
        if config.STRATEGIES.get('orderblock_fvg', False):
            self.breakout_strategies.append(OrderblockFVGStrategy())
        if config.STRATEGIES.get('hma_momentum', False):
            self.breakout_strategies.append(HMAMomentumStrategy())
        if config.STRATEGIES.get('mfi_momentum', False):
            self.breakout_strategies.append(MFIMomentumStrategy())
        
        self.breakout_strategies.append(CCIReversalStrategy())
        
        # íš¡ë³´ì¥ ì „ëµ
        if config.STRATEGIES.get('bollinger_mean_reversion', False):
            self.range_strategies.append(BollingerMeanReversionStrategy())
        if config.STRATEGIES.get('vwap_deviation', False):
            self.range_strategies.append(VWAPDeviationStrategy())
        if config.STRATEGIES.get('range_top_bottom', False):
            self.range_strategies.append(RangeTopBottomStrategy())
        if config.STRATEGIES.get('stoch_rsi_mean_reversion', False):
            self.range_strategies.append(StochRSIMeanReversionStrategy())
        if config.STRATEGIES.get('cmf_divergence', False):
            self.range_strategies.append(CMFDivergenceStrategy())
        
        self.range_strategies.append(WilliamsRStrategy())
        
        self.strategies = self.breakout_strategies + self.range_strategies
        logger.info(f"âœ… ì „ëµ ì´ˆê¸°í™” ì™„ë£Œ: ì´ {len(self.strategies)}ê°œ")
        
        # 3. í™˜ê²½ ì´ˆê¸°í™”
        self.env = TradingEnvironment(
            data_collector=self.data_collector,
            strategies=self.strategies
            # lookbackê³¼ min_holding_timeì€ configì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
        )
        
        # 4. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self._load_scaler()
        
        # 5. ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        
        state_dim = self.env.get_state_dim()
        action_dim = 3  # HOLD, LONG, SHORT
        info_dim = len(self.strategies) + 3  # ì „ëµ ì ìˆ˜ + í¬ì§€ì…˜ ì •ë³´
        
        self.agent = PPOAgent(
            state_dim=state_dim,
            action_dim=action_dim,
            hidden_dim=config.NETWORK_HIDDEN_DIM,
            device=self.device,
            info_dim=info_dim
        )
        
        # 6. ëª¨ë¸ ë¡œë“œ
        self._load_model()
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        self.trades = []  # ê±°ë˜ ë‚´ì—­
        self.equity_curve = []  # ìì‚° ê³¡ì„ 
        self.actions_taken = {'HOLD': 0, 'LONG': 0, 'SHORT': 0}
        
    def _load_scaler(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        try:
            if os.path.exists(self.scaler_path):
                self.env.preprocessor.load(self.scaler_path)
                self.env.scaler_fitted = True
                logger.info(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ: {self.scaler_path}")
            else:
                logger.warning(f"âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.scaler_path}")
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
    
    def _load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            if os.path.exists(self.model_path):
                self.agent.load_model(self.model_path)
                self.agent.model.eval()  # í‰ê°€ ëª¨ë“œ
                logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
            else:
                logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
            raise
    
    def _prepare_test_data(self):
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ 
        Train(70%) / Val(15%) / Test(15%) ê¸°ì¤€ì„ ë”°ë¦„ (train_ppo.pyì™€ ë™ì¼)
        """
        try:
            # 1. ë°ì´í„° ë¡œë“œ (í”¼ì²˜ íŒŒì¼ ìš°ì„ )
            feature_file = 'data/training_features.csv'
            if os.path.exists(feature_file):
                logger.info(f"ğŸ“‚ í”¼ì²˜ ë°ì´í„° ë¡œë“œ: {feature_file}")
                df = pd.read_csv(feature_file, index_col=0, parse_dates=True)
                self.data_collector.eth_data = df
            else:
                logger.warning("âš ï¸ í”¼ì²˜ íŒŒì¼ì´ ì—†ì–´ ì›ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                if self.data_collector.eth_data is None:
                    raise ValueError("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                df = self.data_collector.eth_data

            total_len = len(df)
            
            # 2. ë°ì´í„° ë¶„í•  (train_ppo.pyì™€ ë™ì¼í•œ ê¸°ì¤€ ì ìš©)
            train_end = int(total_len * config.TRAIN_SPLIT)
            val_end = int(total_len * config.VAL_SPLIT)
            
            # í‰ê°€ êµ¬ê°„ ì„¤ì • (ê¸°ë³¸ì ìœ¼ë¡œ Test Setì¸ ë§ˆì§€ë§‰ 15% ì‚¬ìš©)
            # í•„ìš”ì— ë”°ë¼ Validation Set(70%~85%)ì„ í‰ê°€í•  ìˆ˜ë„ ìˆìŒ
            test_start_idx = val_end
            
            logger.info(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {total_len}ê°œ")
            logger.info(f"ğŸ“Š ë°ì´í„° ë¶„í• : Train(0~{train_end}), Val({train_end}~{val_end}), Test({val_end}~{total_len})")
            logger.info(f"ğŸ“Š í‰ê°€ êµ¬ê°„(Test Set): {test_start_idx} ~ {total_len} ({total_len - test_start_idx}ê°œ)")
            
            return test_start_idx, total_len
            
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}", exc_info=True)
            raise
    
    def evaluate(self, initial_capital=10000, max_steps=None, verbose=True):
        """
        ëª¨ë¸ í‰ê°€ ì‹¤í–‰
        
        Args:
            initial_capital: ì´ˆê¸° ìë³¸ê¸ˆ
            max_steps: ìµœëŒ€ í‰ê°€ ìŠ¤í… ìˆ˜ (Noneì´ë©´ ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©)
            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            dict: í‰ê°€ ê²°ê³¼ (ì„±ëŠ¥ ì§€í‘œ í¬í•¨)
        """
        logger.info("=" * 80)
        logger.info("ğŸš€ PPO ëª¨ë¸ í‰ê°€ ì‹œì‘")
        logger.info("=" * 80)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        test_start_idx, total_len = self._prepare_test_data()
        
        # í‰ê°€ ë²”ìœ„ ì„¤ì •
        if max_steps is None:
            max_steps = total_len - test_start_idx
        
        end_idx = min(test_start_idx + max_steps, total_len)
        actual_steps = end_idx - test_start_idx
        
        logger.info(f"ğŸ“Š í‰ê°€ ë²”ìœ„: ì¸ë±ìŠ¤ {test_start_idx} ~ {end_idx} ({actual_steps} ìŠ¤í…)")
        
        # ì´ˆê¸°í™”
        capital = initial_capital
        current_position = None  # {'type': 'LONG' or 'SHORT', 'entry_price': float, 'entry_idx': int}
        entry_price = 0.0
        entry_idx = 0
        
        # [ê°œì„ ] í‰ê°€ ì‹œì‘ ì‹œ LSTM ìƒíƒœ ì´ˆê¸°í™”
        self.agent.reset_episode_states()
        
        self.trades = []
        self.equity_curve = [initial_capital]
        self.actions_taken = {'HOLD': 0, 'LONG': 0, 'SHORT': 0}
        
        total_pnl = 0.0
        winning_trades = 0
        losing_trades = 0
        
        # í‰ê°€ ë£¨í”„
        for step in range(actual_steps):
            current_idx = test_start_idx + step
            
            # í˜„ì¬ ì¸ë±ìŠ¤ ì„¤ì •
            self.data_collector.current_index = current_idx
            
            # í˜„ì¬ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
            if current_idx >= len(self.data_collector.eth_data):
                break
            
            current_candle = self.data_collector.eth_data.iloc[current_idx]
            current_price = current_candle['close']
            
            # í¬ì§€ì…˜ ì •ë³´ ìƒì„±
            if current_position is None:
                position_info = [0.0, 0.0, 0.0]  # [í¬ì§€ì…˜, ë¯¸ì‹¤í˜„PnL, ë³´ìœ ì‹œê°„]
            else:
                # ë¯¸ì‹¤í˜„ PnL ê³„ì‚°
                if current_position['type'] == 'LONG':
                    unrealized_pnl = (current_price - entry_price) / entry_price
                else:  # SHORT
                    unrealized_pnl = (entry_price - current_price) / entry_price
                
                # ë³´ìœ  ì‹œê°„ ì •ê·œí™” (0~1)
                holding_time = (step - entry_idx) / max(actual_steps, 1)
                holding_time = min(holding_time, 1.0)
                
                position_val = 1.0 if current_position['type'] == 'LONG' else -1.0
                position_info = [position_val, unrealized_pnl, holding_time]
            
            # ê´€ì¸¡ ìƒì„±
            obs = self.env.get_observation(position_info)
            if obs is None:
                logger.warning(f"âš ï¸ ê´€ì¸¡ ìƒì„± ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {current_idx})")
                continue
            
            obs_seq, obs_info = obs
            
            # í–‰ë™ ì„ íƒ (í‰ê°€ ëª¨ë“œ: íƒí—˜ ì—†ì´ ê²°ì •ë¡ ì )
            with torch.no_grad():
                action_probs, value = self.agent.model(obs_seq.to(self.device), info=obs_info.to(self.device))
                action = torch.argmax(action_probs, dim=-1).item()
            
            action_names = ['HOLD', 'LONG', 'SHORT']
            action_name = action_names[action]
            self.actions_taken[action_name] += 1
            
            # ê±°ë˜ ì‹¤í–‰
            trade_done = False
            pnl = 0.0
            
            if action == 1:  # LONG
                if current_position is None:
                    # ì§„ì…
                    current_position = {'type': 'LONG', 'entry_price': current_price, 'entry_idx': step}
                    entry_price = current_price
                    entry_idx = step
                    if verbose:
                        logger.info(f"ğŸ“ˆ LONG ì§„ì… | ê°€ê²©: ${current_price:.2f} | ì¸ë±ìŠ¤: {current_idx}")
                elif current_position['type'] == 'SHORT':
                    # ë°˜ëŒ€ í¬ì§€ì…˜ ì „í™˜: SHORT ì²­ì‚° í›„ LONG ì§„ì…
                    # SHORT ì²­ì‚°
                    exit_pnl = (entry_price - current_price) / entry_price
                    pnl = exit_pnl
                    trade_done = True
                    total_pnl += pnl
                    
                    if pnl > 0:
                        winning_trades += 1
                    else:
                        losing_trades += 1
                    
                    self.trades.append({
                        'entry_idx': current_position['entry_idx'],
                        'exit_idx': step,
                        'type': 'SHORT',
                        'entry_price': current_position['entry_price'],
                        'exit_price': current_price,
                        'pnl': pnl,
                        'pnl_pct': pnl * 100
                    })
                    
                    if verbose:
                        logger.info(f"ğŸ“‰ SHORT ì²­ì‚° | ì§„ì…: ${current_position['entry_price']:.2f} | ì²­ì‚°: ${current_price:.2f} | PnL: {pnl*100:.2f}%")
                    
                    # LONG ì§„ì…
                    current_position = {'type': 'LONG', 'entry_price': current_price, 'entry_idx': step}
                    entry_price = current_price
                    entry_idx = step
                    if verbose:
                        logger.info(f"ğŸ“ˆ LONG ì§„ì… | ê°€ê²©: ${current_price:.2f} | ì¸ë±ìŠ¤: {current_idx}")
            
            elif action == 2:  # SHORT
                if current_position is None:
                    # ì§„ì…
                    current_position = {'type': 'SHORT', 'entry_price': current_price, 'entry_idx': step}
                    entry_price = current_price
                    entry_idx = step
                    if verbose:
                        logger.info(f"ğŸ“‰ SHORT ì§„ì… | ê°€ê²©: ${current_price:.2f} | ì¸ë±ìŠ¤: {current_idx}")
                elif current_position['type'] == 'LONG':
                    # ë°˜ëŒ€ í¬ì§€ì…˜ ì „í™˜: LONG ì²­ì‚° í›„ SHORT ì§„ì…
                    # LONG ì²­ì‚°
                    exit_pnl = (current_price - entry_price) / entry_price
                    pnl = exit_pnl
                    trade_done = True
                    total_pnl += pnl
                    
                    if pnl > 0:
                        winning_trades += 1
                    else:
                        losing_trades += 1
                    
                    self.trades.append({
                        'entry_idx': current_position['entry_idx'],
                        'exit_idx': step,
                        'type': 'LONG',
                        'entry_price': current_position['entry_price'],
                        'exit_price': current_price,
                        'pnl': pnl,
                        'pnl_pct': pnl * 100
                    })
                    
                    if verbose:
                        logger.info(f"ğŸ“ˆ LONG ì²­ì‚° | ì§„ì…: ${current_position['entry_price']:.2f} | ì²­ì‚°: ${current_price:.2f} | PnL: {pnl*100:.2f}%")
                    
                    # SHORT ì§„ì…
                    current_position = {'type': 'SHORT', 'entry_price': current_price, 'entry_idx': step}
                    entry_price = current_price
                    entry_idx = step
                    if verbose:
                        logger.info(f"ğŸ“‰ SHORT ì§„ì… | ê°€ê²©: ${current_price:.2f} | ì¸ë±ìŠ¤: {current_idx}")
            
            elif action == 0:  # HOLD
                # í¬ì§€ì…˜ì´ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ëŒ€ê¸°
                pass
            
            # ìì‚° ê³¡ì„  ì—…ë°ì´íŠ¸
            if current_position is not None:
                if current_position['type'] == 'LONG':
                    unrealized_pnl = (current_price - entry_price) / entry_price
                else:
                    unrealized_pnl = (entry_price - current_price) / entry_price
                current_equity = initial_capital * (1 + total_pnl + unrealized_pnl)
            else:
                current_equity = initial_capital * (1 + total_pnl)
            
            self.equity_curve.append(current_equity)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (configì—ì„œ ì„¤ì •í•œ ê°„ê²©)
            if (step + 1) % config.EVAL_VERBOSE_INTERVAL == 0:
                logger.info(f"ì§„í–‰: {step + 1}/{actual_steps} | ìì‚°: ${current_equity:.2f} | ê±°ë˜: {len(self.trades)}íšŒ")
        
        # ë§ˆì§€ë§‰ í¬ì§€ì…˜ ì²­ì‚°
        if current_position is not None:
            final_candle = self.data_collector.eth_data.iloc[min(end_idx - 1, len(self.data_collector.eth_data) - 1)]
            final_price = final_candle['close']
            
            if current_position['type'] == 'LONG':
                exit_pnl = (final_price - entry_price) / entry_price
            else:
                exit_pnl = (entry_price - final_price) / entry_price
            
            pnl = exit_pnl
            total_pnl += pnl
            
            if pnl > 0:
                winning_trades += 1
            else:
                losing_trades += 1
            
            self.trades.append({
                'entry_idx': current_position['entry_idx'],
                'exit_idx': actual_steps - 1,
                'type': current_position['type'],
                'entry_price': current_position['entry_price'],
                'exit_price': final_price,
                'pnl': pnl,
                'pnl_pct': pnl * 100
            })
            
            if verbose:
                logger.info(f"ğŸ”š ìµœì¢… í¬ì§€ì…˜ ì²­ì‚° | {current_position['type']} | ì§„ì…: ${entry_price:.2f} | ì²­ì‚°: ${final_price:.2f} | PnL: {pnl*100:.2f}%")
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        final_equity = initial_capital * (1 + total_pnl)
        total_return = (final_equity - initial_capital) / initial_capital * 100
        
        # ìµœëŒ€ ë‚™í­ ê³„ì‚°
        equity_array = np.array(self.equity_curve)
        peak = np.maximum.accumulate(equity_array)
        drawdown = (equity_array - peak) / peak * 100
        max_drawdown = np.min(drawdown)
        
        # ìŠ¹ë¥  ê³„ì‚°
        total_trades = len(self.trades)
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0.0
        
        # í‰ê·  ìˆ˜ìµ/ì†ì‹¤
        if total_trades > 0:
            pnls = [t['pnl'] for t in self.trades]
            avg_win = np.mean([p for p in pnls if p > 0]) if any(p > 0 for p in pnls) else 0.0
            avg_loss = np.mean([p for p in pnls if p < 0]) if any(p < 0 for p in pnls) else 0.0
            profit_factor = abs(sum([p for p in pnls if p > 0]) / sum([p for p in pnls if p < 0])) if any(p < 0 for p in pnls) else float('inf')
        else:
            avg_win = 0.0
            avg_loss = 0.0
            profit_factor = 0.0
        
        # ìƒ¤í”„ ë¹„ìœ¨ (ê°„ë‹¨ ë²„ì „: ìˆ˜ìµë¥  / ë³€ë™ì„±)
        returns = np.diff(equity_array) / equity_array[:-1]
        sharpe_ratio = np.mean(returns) / (np.std(returns) + 1e-8) * np.sqrt(252 * 288)  # ì—°ìœ¨í™” (3ë¶„ë´‰ ê¸°ì¤€)
        
        # ê²°ê³¼ ì •ë¦¬
        results = {
            'initial_capital': initial_capital,
            'final_equity': final_equity,
            'total_return': total_return,
            'total_trades': total_trades,
            'winning_trades': winning_trades,
            'losing_trades': losing_trades,
            'win_rate': win_rate,
            'avg_win': avg_win * 100,
            'avg_loss': avg_loss * 100,
            'profit_factor': profit_factor,
            'max_drawdown': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'total_pnl': total_pnl * 100,
            'actions_taken': self.actions_taken,
            'trades': self.trades,
            'equity_curve': self.equity_curve
        }
        
        # ê²°ê³¼ ì¶œë ¥
        self._print_results(results)
        
        return results
    
    def _print_results(self, results):
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        logger.info("=" * 80)
        logger.info("ğŸ“Š í‰ê°€ ê²°ê³¼")
        logger.info("=" * 80)
        logger.info(f"ğŸ’° ì´ˆê¸° ìë³¸ê¸ˆ: ${results['initial_capital']:,.2f}")
        logger.info(f"ğŸ’° ìµœì¢… ìì‚°: ${results['final_equity']:,.2f}")
        logger.info(f"ğŸ“ˆ ì´ ìˆ˜ìµë¥ : {results['total_return']:.2f}%")
        logger.info(f"ğŸ“‰ ìµœëŒ€ ë‚™í­: {results['max_drawdown']:.2f}%")
        logger.info(f"ğŸ“Š ìƒ¤í”„ ë¹„ìœ¨: {results['sharpe_ratio']:.2f}")
        logger.info("")
        logger.info(f"ğŸ”„ ì´ ê±°ë˜ íšŸìˆ˜: {results['total_trades']}íšŒ")
        logger.info(f"âœ… ìŠ¹ë¦¬ ê±°ë˜: {results['winning_trades']}íšŒ")
        logger.info(f"âŒ ì†ì‹¤ ê±°ë˜: {results['losing_trades']}íšŒ")
        logger.info(f"ğŸ¯ ìŠ¹ë¥ : {results['win_rate']:.2f}%")
        logger.info(f"ğŸ“Š í‰ê·  ìˆ˜ìµ: {results['avg_win']:.2f}%")
        logger.info(f"ğŸ“Š í‰ê·  ì†ì‹¤: {results['avg_loss']:.2f}%")
        logger.info(f"ğŸ’ ìˆ˜ìµ íŒ©í„°: {results['profit_factor']:.2f}")
        logger.info("")
        logger.info("ğŸ² í–‰ë™ ë¶„í¬:")
        for action, count in results['actions_taken'].items():
            logger.info(f"   {action}: {count}íšŒ ({count/sum(results['actions_taken'].values())*100:.1f}%)")
        logger.info("=" * 80)
        
        # ìƒìœ„/í•˜ìœ„ ê±°ë˜ ì¶œë ¥
        if len(results['trades']) > 0:
            pnls = [(i, t['pnl_pct']) for i, t in enumerate(results['trades'])]
            pnls.sort(key=lambda x: x[1], reverse=True)
            
            logger.info("ğŸ† ìƒìœ„ 5ê°œ ê±°ë˜:")
            for i, (idx, pnl) in enumerate(pnls[:5]):
                trade = results['trades'][idx]
                logger.info(f"   {i+1}. {trade['type']} | ì§„ì…: ${trade['entry_price']:.2f} | ì²­ì‚°: ${trade['exit_price']:.2f} | PnL: {pnl:.2f}%")
            
            logger.info("")
            logger.info("ğŸ“‰ í•˜ìœ„ 5ê°œ ê±°ë˜:")
            for i, (idx, pnl) in enumerate(pnls[-5:]):
                trade = results['trades'][idx]
                logger.info(f"   {i+1}. {trade['type']} | ì§„ì…: ${trade['entry_price']:.2f} | ì²­ì‚°: ${trade['exit_price']:.2f} | PnL: {pnl:.2f}%")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # í‰ê°€ê¸° ì´ˆê¸°í™”
        evaluator = PPOModelEvaluator(test_split=0.2)
        
        # í‰ê°€ ì‹¤í–‰
        results = evaluator.evaluate(
            initial_capital=10000,
            max_steps=None,  # ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©
            verbose=True
        )
        
        logger.info("âœ… í‰ê°€ ì™„ë£Œ!")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return None


if __name__ == '__main__':
    main()
