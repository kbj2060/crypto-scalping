"""
DDQN ëª¨ë¸ í‰ê°€(Backtest) ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ ëª¨ë¸(best_ddqn_model.pth)ì„ ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° êµ¬ê°„ì—ì„œ ì„±ëŠ¥ ì¸¡ì •
train_dqn.pyì™€ ë™ì¼í•œ Feature Engineering íŒŒì´í”„ë¼ì¸ ì ìš©
"""
import sys
import os
import json
import torch
import numpy as np
import pandas as pd
import logging
import matplotlib.pyplot as plt

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.data_collector import DataCollector
from model.dqn_agent import DDQNAgent
from model.trading_env import TradingEnvironment
from model.feature_engineering import FeatureEngineer
from model.mtf_processor import MTFProcessor
from model.train_dqn import precalculate_strategy_scores  # í•™ìŠµ ì½”ë“œì˜ ì „ëµ ê³„ì‚° í•¨ìˆ˜ ì¬ì‚¬ìš©
import config

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelEvaluator:
    def __init__(self, model_path='saved_models/best_ddqn_model.pth'):
        self.model_path = model_path
        self.data_collector = DataCollector(use_saved_data=True)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # ë°ì´í„° ë¡œë“œ
        if not self.data_collector.load_saved_data():
            raise ValueError("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            
        # ---------------------------------------------------------------------
        # 1. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (í•™ìŠµê³¼ ë™ì¼í•œ íŒŒì´í”„ë¼ì¸)
        # ---------------------------------------------------------------------
        logger.info("ğŸ› ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘...")
        
        # 1-1. ê³ ê¸‰ í”¼ì²˜ ìƒì„±
        btc_df = getattr(self.data_collector, 'btc_data', None)
        engineer = FeatureEngineer(self.data_collector.eth_data, btc_df)
        enhanced_df = engineer.generate_features()
        self.data_collector.eth_data = enhanced_df
        
        # 1-2. MTF í”¼ì²˜ ìƒì„±
        if not isinstance(self.data_collector.eth_data.index, pd.DatetimeIndex):
            if 'timestamp' in self.data_collector.eth_data.columns:
                self.data_collector.eth_data.index = pd.to_datetime(self.data_collector.eth_data['timestamp'], unit='ms')
            else:
                self.data_collector.eth_data.index = pd.to_datetime(self.data_collector.eth_data.index)
        
        mtf_processor = MTFProcessor(self.data_collector.eth_data)
        self.data_collector.eth_data = mtf_processor.add_mtf_features()
        
        # 1-3. ì „ëµ ì ìˆ˜ ê³„ì‚° (train_dqnì˜ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        # ì£¼ì˜: ì „ëµì´ ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ train_dqn.pyì˜ precalculate í•¨ìˆ˜ê°€ ìµœì‹ ì´ì–´ì•¼ í•¨
        logger.info("ğŸ§  ì „ëµ ì‹ í˜¸ ê³„ì‚° ì¤‘...")
        strat_df = precalculate_strategy_scores(self.data_collector, force_recalculate=False)
        
        # ì¸ë±ìŠ¤ ì •ë ¬ ë° ë³‘í•©
        if not strat_df.index.equals(self.data_collector.eth_data.index):
            strat_df = strat_df.reindex(self.data_collector.eth_data.index).fillna(0)
            
        for col in strat_df.columns:
            self.data_collector.eth_data[col] = strat_df[col]
            
        # ---------------------------------------------------------------------
        # 2. í•™ìŠµëœ í”¼ì²˜ ëª©ë¡ ë¡œë“œ
        # ---------------------------------------------------------------------
        features_json_path = 'saved_models/selected_features.json'
        if os.path.exists(features_json_path):
            with open(features_json_path, 'r') as f:
                self.feature_columns = json.load(f)
            logger.info(f"ğŸ“‚ í•™ìŠµëœ í”¼ì²˜ ëª©ë¡ ë¡œë“œ: {len(self.feature_columns)}ê°œ")
        else:
            logger.warning("âš ï¸ í”¼ì²˜ ëª©ë¡ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. config.FEATURE_COLUMNS ì‚¬ìš©")
            self.feature_columns = config.FEATURE_COLUMNS
            
        # ëˆ„ë½ëœ ì»¬ëŸ¼ 0ìœ¼ë¡œ ì±„ìš°ê¸°
        for col in self.feature_columns:
            if col not in self.data_collector.eth_data.columns:
                self.data_collector.eth_data[col] = 0.0
                
        # ---------------------------------------------------------------------
        # 3. í™˜ê²½ ë° ì—ì´ì „íŠ¸ ì„¤ì •
        # ---------------------------------------------------------------------
        self.env = TradingEnvironment(
            self.data_collector,
            strategies=[],
            lookback=config.LOOKBACK_WINDOW,
            selected_features=self.feature_columns
        )
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        scaler_path = 'saved_models/scaler.pkl'
        if self.env.preprocessor.load_scaler(scaler_path):
            self.env.scaler_fitted = True
            logger.info("âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²°ê³¼ê°€ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        ddqn_config = config.DDQN_CONFIG
        self.agent = DDQNAgent(
            input_dim=len(self.feature_columns),
            hidden_dim=ddqn_config['hidden_dim'],
            num_layers=ddqn_config['num_layers'],
            action_dim=ddqn_config['action_dim'],
            device=self.device,
            epsilon_start=0.0,  # í‰ê°€ ëª¨ë“œ: íƒí—˜ ì—†ìŒ
            epsilon_end=0.0,
            use_per=config.USE_PER,
            n_step=config.N_STEP
        )
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        if os.path.exists(self.model_path):
            self.agent.load_model(self.model_path)
            self.agent.policy_net.eval()
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
        else:
            raise ValueError(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {self.model_path}")

    def run_backtest(self, start_index=None, steps=2000):
        """ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info(f"ğŸš€ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ (Steps: {steps})")
        
        # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì„¤ì • (ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš©)
        total_len = len(self.data_collector.eth_data)
        if start_index is None:
            start_index = total_len - steps - 100
            if start_index < config.LOOKBACK_WINDOW:
                start_index = config.LOOKBACK_WINDOW
        
        self.data_collector.current_index = start_index
        
        balance = 1000.0  # ì´ˆê¸° ìë³¸ $1000
        initial_balance = balance
        position = None  # 'LONG', 'SHORT', None
        entry_price = 0.0
        entry_idx = 0
        
        history = []
        equity_curve = [balance]
        
        # ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„
        for i in range(steps):
            if self.data_collector.current_index >= total_len - 1:
                break
                
            # 1. ê´€ì¸¡
            # í¬ì§€ì…˜ ì •ë³´ êµ¬ì„±
            pos_val = 1.0 if position == 'LONG' else (-1.0 if position == 'SHORT' else 0.0)
            pnl_val = 0.0
            hold_val = 0.0
            
            current_price = float(self.data_collector.eth_data.iloc[self.data_collector.current_index]['close'])
            
            if position:
                if position == 'LONG':
                    pnl_val = (current_price - entry_price) / entry_price
                else:
                    pnl_val = (entry_price - current_price) / entry_price
                hold_val = min(1.0, (self.data_collector.current_index - entry_idx) / 160.0)
            
            state = self.env.get_observation(position_info=[pos_val, pnl_val * 10, hold_val])
            
            if state is None:
                self.data_collector.current_index += 1
                continue
                
            # 2. í–‰ë™ ê²°ì • (Greedy)
            action = self.agent.act(state, training=False)
            
            # 3. ë§¤ë§¤ ë¡œì§
            # 0: HOLD, 1: LONG, 2: SHORT
            new_position = position
            trade_pnl = 0.0
            fee_rate = 0.0005  # 0.05%
            
            if action == 1:  # LONG ì‹ í˜¸
                if position == 'SHORT':  # ìˆ ì²­ì‚° í›„ ë¡±
                    # ì²­ì‚°
                    pnl = (entry_price - current_price) / entry_price
                    realized_pnl = pnl - fee_rate
                    balance *= (1 + realized_pnl)
                    history.append({'type': 'CLOSE_SHORT', 'price': current_price, 'pnl': realized_pnl, 'balance': balance})
                    
                    # ì§„ì…
                    balance *= (1 - fee_rate)  # ì§„ì… ìˆ˜ìˆ˜ë£Œ
                    entry_price = current_price
                    entry_idx = self.data_collector.current_index
                    new_position = 'LONG'
                    history.append({'type': 'OPEN_LONG', 'price': current_price, 'balance': balance})
                    
                elif position is None:  # ì‹ ê·œ ë¡±
                    balance *= (1 - fee_rate)
                    entry_price = current_price
                    entry_idx = self.data_collector.current_index
                    new_position = 'LONG'
                    history.append({'type': 'OPEN_LONG', 'price': current_price, 'balance': balance})
                    
            elif action == 2:  # SHORT ì‹ í˜¸
                if position == 'LONG':  # ë¡± ì²­ì‚° í›„ ìˆ
                    # ì²­ì‚°
                    pnl = (current_price - entry_price) / entry_price
                    realized_pnl = pnl - fee_rate
                    balance *= (1 + realized_pnl)
                    history.append({'type': 'CLOSE_LONG', 'price': current_price, 'pnl': realized_pnl, 'balance': balance})
                    
                    # ì§„ì…
                    balance *= (1 - fee_rate)
                    entry_price = current_price
                    entry_idx = self.data_collector.current_index
                    new_position = 'SHORT'
                    history.append({'type': 'OPEN_SHORT', 'price': current_price, 'balance': balance})
                    
                elif position is None:  # ì‹ ê·œ ìˆ
                    balance *= (1 - fee_rate)
                    entry_price = current_price
                    entry_idx = self.data_collector.current_index
                    new_position = 'SHORT'
                    history.append({'type': 'OPEN_SHORT', 'price': current_price, 'balance': balance})
            
            position = new_position
            equity_curve.append(balance)
            self.data_collector.current_index += 1
            
        # ê²°ê³¼ ë¶„ì„
        self._print_stats(initial_balance, balance, history, equity_curve)
        
    def _print_stats(self, initial, final, history, equity):
        """ì„±ê³¼ ë¶„ì„ ì¶œë ¥"""
        trades = [h for h in history if 'pnl' in h]
        wins = [t for t in trades if t['pnl'] > 0]
        
        total_return = (final - initial) / initial * 100
        win_rate = len(wins) / len(trades) * 100 if trades else 0
        
        # MDD ê³„ì‚°
        equity = np.array(equity)
        peak = np.maximum.accumulate(equity)
        drawdown = (peak - equity) / peak
        mdd = drawdown.max() * 100
        
        print("\n" + "="*50)
        print(f"ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ (êµ¬ê°„: {len(equity)} ìº”ë“¤)")
        print("="*50)
        print(f"ğŸ’° ì´ˆê¸° ìë³¸: ${initial:.2f}")
        print(f"ğŸ’° ìµœì¢… ìë³¸: ${final:.2f}")
        print(f"ğŸ“ˆ ì´ ìˆ˜ìµë¥ : {total_return:.2f}%")
        print(f"ğŸ“‰ MDD (ìµœëŒ€ ë‚™í­): {mdd:.2f}%")
        print(f"ğŸ² ì´ ê±°ë˜ íšŸìˆ˜: {len(trades)}íšŒ")
        print(f"ğŸ¯ ìŠ¹ë¥ : {win_rate:.2f}%")
        
        if trades:
            avg_pnl = np.mean([t['pnl'] for t in trades]) * 100
            print(f"âš–ï¸ í‰ê·  ì†ìµ: {avg_pnl:.4f}%")
        print("="*50 + "\n")
        
        # ìˆ˜ìµ ê³¡ì„  ê·¸ë˜í”„
        plt.figure(figsize=(12, 6))
        plt.plot(equity, label='Equity Curve')
        plt.title(f'Backtest Result (Return: {total_return:.2f}%)')
        plt.xlabel('Steps')
        plt.ylabel('Balance ($)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()

if __name__ == '__main__':
    try:
        evaluator = ModelEvaluator()
        # ìµœê·¼ 2000ê°œ ë°ì´í„°(ì•½ 4ì¼ì¹˜)ë¡œ í…ŒìŠ¤íŠ¸
        evaluator.run_backtest(steps=2000)
    except Exception as e:
        logger.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
