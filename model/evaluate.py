"""
DDQN ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (Evaluation Mode)
íƒí—˜(Epsilon)ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ AIì˜ 'ìˆœìˆ˜ ì‹¤ë ¥'ë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""
import sys
import os
import torch
import numpy as np
import logging
import matplotlib.pyplot as plt

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from model.train_dqn import DDQNTrainer
import config

# ë¡œê¹… ì„¤ì •
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/evaluate.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def evaluate(episodes=10):
    """
    DDQN ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
    
    Args:
        episodes (int): í‰ê°€í•  ì—í”¼ì†Œë“œ ìˆ˜
    """
    logger.info("=" * 60)
    logger.info("ğŸ§ª DDQN ëª¨ë¸ í‰ê°€ ëª¨ë“œ ì‹œì‘ (íƒí—˜ë¥  0.0% - ìˆœìˆ˜ ì‹¤ë ¥ ê²€ì¦)")
    logger.info("=" * 60)

    # 1. í•™ìŠµ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    # (XGBoost í”¼ì²˜ ì„ íƒ ë“± ëª¨ë“  ì „ì²˜ë¦¬ ê³¼ì •ì„ ë™ì¼í•˜ê²Œ ìˆ˜í–‰)
    try:
        trainer = DDQNTrainer(force_recalculate_strategies=False)
    except Exception as e:
        logger.error(f"íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        return

    # 2. í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model_path = config.DDQN_MODEL_PATH
    if os.path.exists(model_path):
        try:
            trainer.agent.load_model(model_path)
            logger.info(f"ğŸ’¾ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
            return
    else:
        logger.error(f"âŒ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return

    # 3. [í•µì‹¬] íƒí—˜(Epsilon)ì„ ê°•ì œë¡œ 0ìœ¼ë¡œ ì„¤ì •
    trainer.agent.epsilon = 0.0
    trainer.agent.epsilon_end = 0.0  # epsilon_endë„ 0ìœ¼ë¡œ ì„¤ì •
    
    # 4. ì‹ ê²½ë§ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout ë¹„í™œì„±í™” ë“±)
    trainer.agent.policy_net.eval()
    trainer.agent.target_net.eval()
    
    # 5. [í•µì‹¬] í•™ìŠµì„ ë¹„í™œì„±í™”í•˜ê¸° ìœ„í•´ train_stepì„ ì„ì‹œë¡œ ì˜¤ë²„ë¼ì´ë“œ
    original_train_step = trainer.agent.train_step
    def no_train_step():
        """í‰ê°€ ëª¨ë“œì—ì„œëŠ” í•™ìŠµí•˜ì§€ ì•ŠìŒ"""
        return None
    trainer.agent.train_step = no_train_step
    
    eval_rewards = []
    eval_steps = []
    
    # 5. í‰ê°€ ë£¨í”„ ì‹¤í–‰
    logger.info(f"ğŸ“Š í‰ê°€ ì‹œì‘: {episodes}ê°œ ì—í”¼ì†Œë“œ")
    logger.info("-" * 60)
    
    for ep in range(1, episodes + 1):
        try:
            # train_episode í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë˜, agent.epsilonì´ 0ì´ë¯€ë¡œ í•­ìƒ ìµœì  í–‰ë™ ì„ íƒ
            # train_stepì´ ì˜¤ë²„ë¼ì´ë“œë˜ì–´ ìˆìœ¼ë¯€ë¡œ í•™ìŠµì€ ìˆ˜í–‰ë˜ì§€ ì•ŠìŒ
            result = trainer.train_episode(ep, max_steps=1000)
            
            if result:
                reward, steps = result
                eval_rewards.append(reward)
                eval_steps.append(steps)
                logger.info(f"ğŸ“ Test Ep {ep}/{episodes}: Score {reward:.2f} | Steps {steps} (100% ì‹¤ë ¥ ë§¤ë§¤)")
            else:
                logger.warning(f"âš ï¸ Ep {ep}: ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ìŠ¤í‚µë¨")
                
        except Exception as e:
            logger.error(f"ì—í”¼ì†Œë“œ {ep} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            continue

    if len(eval_rewards) == 0:
        logger.error("âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 6. ê²°ê³¼ ë¶„ì„
    avg_score = np.mean(eval_rewards)
    std_score = np.std(eval_rewards)
    max_score = np.max(eval_rewards)
    min_score = np.min(eval_rewards)
    positive_episodes = sum(1 for r in eval_rewards if r > 0)
    win_rate = (positive_episodes / len(eval_rewards)) * 100
    
    logger.info("=" * 60)
    logger.info(f"ğŸ“Š í‰ê°€ ì¢…ë£Œ (ì´ {len(eval_rewards)}íšŒ ì„±ê³µ)")
    logger.info(f"ğŸ† í‰ê·  ì ìˆ˜: {avg_score:.2f} Â± {std_score:.2f}")
    logger.info(f"ğŸ“ˆ ìµœê³  ì ìˆ˜: {max_score:.2f}")
    logger.info(f"ğŸ“‰ ìµœì € ì ìˆ˜: {min_score:.2f}")
    logger.info(f"âœ… ìˆ˜ìµ ì—í”¼ì†Œë“œ: {positive_episodes}/{len(eval_rewards)} ({win_rate:.1f}%)")
    logger.info("=" * 60)
    
    # ì§„ë‹¨ ë©”ì‹œì§€
    if avg_score > 50:
        logger.info("âœ… ì§„ë‹¨: AIê°€ ì•„ì£¼ í›Œë¥­í•œ ìˆ˜ìµ ëª¨ë¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤!")
    elif avg_score > 20:
        logger.info("âœ… ì§„ë‹¨: AIê°€ ì•ˆì •ì ì¸ ìˆ˜ìµì„ ë‚´ê³  ìˆìŠµë‹ˆë‹¤.")
    elif avg_score > 0:
        logger.info("âš ï¸ ì§„ë‹¨: ìˆ˜ìµì„ ë‚´ê³ ëŠ” ìˆì§€ë§Œ, ë” ì •êµí•œ íŠœë‹ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    elif avg_score > -20:
        logger.info("âš ï¸ ì§„ë‹¨: ì†ì‹¤ì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. í•™ìŠµ íŒŒë¼ë¯¸í„° ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        logger.info("âŒ ì§„ë‹¨: í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ëª¨ë¸ êµ¬ì¡°/ë³´ìƒ ì¬ê²€í†  í•„ìš”)")
    
    # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    try:
        plt.figure(figsize=(12, 6))
        
        # ì„œë¸Œí”Œë¡¯ 1: ì—í”¼ì†Œë“œë³„ ì ìˆ˜
        plt.subplot(1, 2, 1)
        colors = ['green' if r > 0 else 'red' for r in eval_rewards]
        plt.bar(range(1, len(eval_rewards) + 1), eval_rewards, color=colors, alpha=0.7)
        plt.axhline(y=avg_score, color='blue', linestyle='--', linewidth=2, label=f'Avg: {avg_score:.2f}')
        plt.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.3)
        plt.title('Evaluation Performance (Zero Epsilon)')
        plt.xlabel('Episode')
        plt.ylabel('Total Reward')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ì„œë¸Œí”Œë¡¯ 2: ì ìˆ˜ ë¶„í¬
        plt.subplot(1, 2, 2)
        plt.hist(eval_rewards, bins=min(20, len(eval_rewards)), color='skyblue', alpha=0.7, edgecolor='black')
        plt.axvline(x=avg_score, color='red', linestyle='--', linewidth=2, label=f'Mean: {avg_score:.2f}')
        plt.axvline(x=0, color='black', linestyle='-', linewidth=1, alpha=0.3)
        plt.title('Reward Distribution')
        plt.xlabel('Total Reward')
        plt.ylabel('Frequency')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('logs/evaluation_result.png', dpi=150)
        plt.close()
        logger.info("ğŸ“Š ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: logs/evaluation_result.png")
    except Exception as e:
        logger.warning(f"ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='DDQN ëª¨ë¸ í‰ê°€')
    parser.add_argument('--episodes', type=int, default=10, help='í‰ê°€í•  ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸: 10)')
    
    args = parser.parse_args()
    
    try:
        evaluate(episodes=args.episodes)
    except KeyboardInterrupt:
        logger.info("í‰ê°€ ì¤‘ë‹¨")
    except Exception as e:
        logger.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
