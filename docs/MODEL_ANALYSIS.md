# Model êµ¬ì¡° ë° ë°ì´í„° íë¦„ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ë°ì´í„° íë¦„ (Data Flow)

### 1. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸

```
ì›ë³¸ ë°ì´í„° (ETH/USDT)
    â†“
FeatureEngineer.generate_features()
    â”œâ”€ ê°€ê²© & ë³€ë™ì„± (9ê°œ): log_return, roll_return_6, atr_ratio, bb_width, bb_pos, rsi, macd_hist, hma_ratio, cci
    â”œâ”€ ê±°ë˜ëŸ‰ & ì˜¤ë”í”Œë¡œìš° (6ê°œ): rvol, taker_ratio, cvd_change, mfi, cmf, vwap_dist
    â”œâ”€ íŒ¨í„´ & ìœ ë™ì„± (5ê°œ): wick_upper, wick_lower, range_pos, swing_break, chop
    â””â”€ ì‹œì¥ ìƒê´€ê´€ê³„ (5ê°œ): btc_return, btc_rsi, btc_corr, btc_vol, eth_btc_ratio
    â†“
MTFProcessor.add_mtf_features()
    â””â”€ ìƒìœ„ í”„ë ˆì„ ì§€í‘œ (4ê°œ): rsi_15m, trend_15m, rsi_1h, trend_1h
    â†“
precalculate_strategy_scores()
    â””â”€ ì „ëµ ì ìˆ˜ (12ê°œ): strat_btc_eth_corr, strat_vol_squeeze, ..., strat_cci_reversal, strat_williams_r
    â†“
XGBoost Feature Selection (ì„ íƒì )
    â””â”€ TOP_K_FEATURES (ê¸°ë³¸ 25ê°œ) ì„ íƒ
    â†“
ìµœì¢… í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (ì•½ 20~30ê°œ)
```

### 2. í•™ìŠµ íŒŒì´í”„ë¼ì¸

```
DDQNTrainer.__init__()
    â”œâ”€ ë°ì´í„° ë¡œë“œ
    â”œâ”€ FeatureEngineer ì ìš©
    â”œâ”€ MTFProcessor ì ìš©
    â”œâ”€ ì „ëµ ì ìˆ˜ ê³„ì‚°
    â”œâ”€ XGBoost í”¼ì²˜ ì„ íƒ (ì„ íƒì )
    â”œâ”€ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ (_fit_global_scaler)
    â””â”€ DDQNAgent ì´ˆê¸°í™”
    â†“
train_episode()
    â”œâ”€ ëœë¤ ì‹œì‘ì  ì„ íƒ
    â”œâ”€ ê° ìŠ¤í…ë§ˆë‹¤:
    â”‚   â”œâ”€ get_observation() â†’ (obs_seq, obs_info)
    â”‚   â”œâ”€ agent.act() â†’ action
    â”‚   â”œâ”€ ë§¤ë§¤ ë¡œì§ ì‹¤í–‰
    â”‚   â”œâ”€ calculate_reward() â†’ reward
    â”‚   â”œâ”€ agent.remember() â†’ N-step ë²„í¼ì— ì €ì¥
    â”‚   â””â”€ agent.train_step() â†’ í•™ìŠµ
    â””â”€ ì—í”¼ì†Œë“œ ì¢…ë£Œ
```

## ğŸ” ë°œê²¬ëœ ë¬¸ì œì 

### âŒ **ì¹˜ëª…ì  ë¬¸ì œ 1: obs_infoê°€ ëª¨ë¸ì— ì „ë‹¬ë˜ì§€ ì•ŠìŒ**

**í˜„ì¬ ìƒí™©:**
- `trading_env.py`: `(obs_seq, obs_info)` íŠœí”Œ ë°˜í™˜
- `dqn_agent.py`ì˜ `act()`: `obs_seq`ë§Œ ì‚¬ìš©
- `DuelingGRU` ëª¨ë¸: `obs_seq`ë§Œ ë°›ìŒ
- **ê²°ê³¼**: í¬ì§€ì…˜ ì •ë³´(3ì°¨ì›)ê°€ ëª¨ë¸ì— ì „ë‹¬ë˜ì§€ ì•ŠìŒ!

**ì˜í–¥:**
- ëª¨ë¸ì´ í˜„ì¬ í¬ì§€ì…˜ ìƒíƒœ, PnL, ë³´ìœ  ì‹œê°„ì„ ì•Œ ìˆ˜ ì—†ìŒ
- ë™ì¼í•œ ì°¨íŠ¸ íŒ¨í„´ì´ë¼ë„ í¬ì§€ì…˜ì— ë”°ë¼ ë‹¤ë¥¸ í–‰ë™ì´ í•„ìš”í•œë° êµ¬ë¶„ ë¶ˆê°€

**ìˆ˜ì • í•„ìš”:**
```python
# dqn_model.pyì˜ DuelingGRU.forward() ìˆ˜ì •
def forward(self, x, info=None):
    # x: (batch, seq, input_dim)
    # info: (batch, 3) - í¬ì§€ì…˜ ì •ë³´
    
    # ê¸°ì¡´ ë¡œì§...
    context_vector = self.attention(gru_out)
    
    # [ì¶”ê°€] info í†µí•©
    if info is not None:
        context_vector = torch.cat([context_vector, info], dim=-1)
        # ë˜ëŠ” ë³„ë„ FC ë ˆì´ì–´ë¡œ í†µí•©
    
    value = self.value_stream(context_vector)
    advantage = self.advantage_stream(context_vector)
    ...
```

### âš ï¸ **ë¬¸ì œ 2: ìŠ¤ì¼€ì¼ëŸ¬ ì°¨ì› ë¶ˆì¼ì¹˜ (ë¶€ë¶„ í•´ê²°ë¨)**

**í˜„ì¬ ìƒí™©:**
- `scaler_feature_order`ë¡œ ìˆœì„œ ë³´ì¥ ì‹œë„
- í•˜ì§€ë§Œ `trading_env.py`ì—ì„œ í”¼ì²˜ ë§¤í•‘ ì‹œ ì¸ë±ìŠ¤ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±

**ê°œì„  í•„ìš”:**
- ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì‹œ í”¼ì²˜ ì´ë¦„ë„ í•¨ê»˜ ì €ì¥
- ë¡œë“œ ì‹œ í”¼ì²˜ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘ (ì¸ë±ìŠ¤ ëŒ€ì‹ )

### âš ï¸ **ë¬¸ì œ 3: N-step ë²„í¼ ë°ì´í„° ìœ ì‹¤ ê°€ëŠ¥ì„±**

**í˜„ì¬ ë¡œì§:**
```python
# dqn_agent.pyì˜ remember()
while self.n_step_buffer:
    if len(self.n_step_buffer) < self.n_step and not done:
        break  # doneì´ ì•„ë‹ˆë©´ Nê°œ ì°° ë•Œê¹Œì§€ ëŒ€ê¸°
```

**ë¬¸ì œ:**
- ì—í”¼ì†Œë“œê°€ ëë‚˜ì§€ ì•Šìœ¼ë©´ ë²„í¼ì— ë‚¨ì€ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
- ë§ˆì§€ë§‰ N-1ê°œ ê²½í—˜ì´ ì†ì‹¤ë  ìˆ˜ ìˆìŒ

**ê°œì„  í•„ìš”:**
- ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ ë²„í¼ flush ë¡œì§ ê°•í™”

### âš ï¸ **ë¬¸ì œ 4: NoisyNet ì‚¬ìš©ë²•**

**í˜„ì¬:**
- ë§¤ ìŠ¤í…ë§ˆë‹¤ `reset_noise()` í˜¸ì¶œ
- ì´ëŠ” ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•ì´ì§€ë§Œ, í•™ìŠµ íš¨ìœ¨ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒ

**ê¶Œì¥:**
- ì—í”¼ì†Œë“œ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¦¬ì…‹ (í˜„ì¬ëŠ” ë§¤ ìŠ¤í…)
- ë˜ëŠ” ë°°ì¹˜ í•™ìŠµ ì „ì—ë§Œ ë¦¬ì…‹

### âš ï¸ **ë¬¸ì œ 5: ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ (ë¶€ë¶„ í•´ê²°ë¨)**

**í˜„ì¬:**
- ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ì‹œ 80% êµ¬ê°„ë§Œ ì‚¬ìš© (ì¢‹ìŒ)
- í•˜ì§€ë§Œ ì „ëµ ì ìˆ˜ ê³„ì‚°ì€ ì „ì²´ ë°ì´í„° ì‚¬ìš©

**ê°œì„  í•„ìš”:**
- ì „ëµ ì ìˆ˜ë„ í•™ìŠµ êµ¬ê°„ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì œí•œ

## âœ… ì˜ êµ¬í˜„ëœ ë¶€ë¶„

1. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: FeatureEngineerë¡œ ì²´ê³„ì  ê´€ë¦¬
2. **MTF ì²˜ë¦¬**: Look-ahead bias ë°©ì§€ (shift ì ìš©)
3. **ìŠ¤ì¼€ì¼ëŸ¬ ìˆœì„œ ë³´ì¥**: `scaler_feature_order` ì‚¬ìš©
4. **N-step Learning**: êµ¬í˜„ ì™„ë£Œ
5. **PER**: êµ¬í˜„ ì™„ë£Œ
6. **ë³´ìƒ í•¨ìˆ˜**: í˜„ì‹¤ì ì¸ ë²„ì „ìœ¼ë¡œ ê°œì„ ë¨

## ğŸ› ï¸ ê°œì„  ì œì•ˆ

### 1. **obs_info í†µí•© (ìµœìš°ì„ )**

```python
# dqn_model.py ìˆ˜ì •
class DuelingGRU(nn.Module):
    def __init__(self, input_dim, hidden_dim=128, num_layers=2, action_dim=3, 
                 info_dim=3, noisy=True):  # info_dim ì¶”ê°€
        ...
        # Info í†µí•© ë ˆì´ì–´ ì¶”ê°€
        self.info_proj = nn.Linear(info_dim, hidden_dim // 4)
        self.final_dim = hidden_dim + hidden_dim // 4
        
        self.value_stream = nn.Sequential(
            LinearLayer(self.final_dim, 128),  # hidden_dim -> final_dim
            ...
        )
    
    def forward(self, x, info=None):
        # ê¸°ì¡´ ë¡œì§...
        context_vector = self.attention(gru_out)
        
        # Info í†µí•©
        if info is not None:
            info_proj = self.info_proj(info)
            context_vector = torch.cat([context_vector, info_proj], dim=-1)
        else:
            # Infoê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
            info_proj = torch.zeros(context_vector.size(0), hidden_dim // 4).to(context_vector.device)
            context_vector = torch.cat([context_vector, info_proj], dim=-1)
        
        value = self.value_stream(context_vector)
        ...
```

### 2. **ìŠ¤ì¼€ì¼ëŸ¬ í”¼ì²˜ ì´ë¦„ ì €ì¥**

```python
# preprocess.py ìˆ˜ì •
def save_scaler(self, path='saved_models/scaler.pkl', feature_names=None):
    data = {
        'mean': self.mean,
        'std': self.std,
        'feature_names': feature_names  # ì¶”ê°€
    }
    pickle.dump(data, f)
```

### 3. **N-step ë²„í¼ ì™„ì „ flush**

```python
# dqn_agent.pyì˜ remember() ìˆ˜ì •
def remember(self, state, action, reward, next_state, done):
    self.n_step_buffer.append((state, action, reward, next_state, done))
    
    # Flush ë¡œì§ ê°œì„ 
    while len(self.n_step_buffer) >= self.n_step or (done and len(self.n_step_buffer) > 0):
        current_n = min(self.n_step, len(self.n_step_buffer))
        # ... ê¸°ì¡´ ë¡œì§
```

### 4. **NoisyNet ë¦¬ì…‹ ìµœì í™”**

```python
# train_dqn.py ìˆ˜ì •
# ì—í”¼ì†Œë“œ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¦¬ì…‹
if hasattr(self.agent, 'reset_noise'):
    self.agent.reset_noise()

# ìŠ¤í… ë‚´ë¶€ì—ì„œëŠ” ë¦¬ì…‹í•˜ì§€ ì•ŠìŒ
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” ì œì•ˆ

1. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: í˜„ì¬ 64 â†’ 128ë¡œ ì¦ê°€ ê³ ë ¤
2. **Target Update ì£¼ê¸°**: í˜„ì¬ 1000 â†’ 500ìœ¼ë¡œ ë‹¨ì¶• ê³ ë ¤
3. **Learning Rate ìŠ¤ì¼€ì¤„ë§**: ê³ ì • LR ëŒ€ì‹  Cosine Annealing ê³ ë ¤
4. **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘**: í˜„ì¬ 1.0 â†’ 0.5ë¡œ ì¡°ì • ê³ ë ¤

## ğŸ”’ ì•ˆì •ì„± ê°œì„ 

1. **NaN/Inf ì²´í¬ ê°•í™”**: ëª¨ë“  í…ì„œ ì—°ì‚° í›„ ì²´í¬
2. **ì—ëŸ¬ í•¸ë“¤ë§**: try-except ë¸”ë¡ ì¶”ê°€
3. **ë¡œê¹… ê°•í™”**: ì¤‘ìš”í•œ ë‹¨ê³„ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
